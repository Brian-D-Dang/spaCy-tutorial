{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92971223",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948eab2",
   "metadata": {},
   "source": [
    "## Basics of spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dddf4014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x16ac0ddf3a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "txt = \"The tallest living man is 37-year-old Sultan Kosen, from Turkey, who is 8 feet, 2.8 inches, who set the record in 2009.\"\n",
    "\n",
    "# Create the Language object\n",
    "# convention to name any loaded language models 'nlp' in spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ed0a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The tallest living man is 37-year-old Sultan Kosen, from Turkey, who is 8 feet, 2.8 inches, who set the record in 2009."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how we create a doc object\n",
    "doc = nlp(txt)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c4a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "tallest\n",
      "living\n",
      "man\n",
      "is\n",
      "\n",
      "Text length: 31\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# a doc object is a convention and an iterator\n",
    "# slicing and indexing notations can be used to extract individual tokens\n",
    "for token in doc[:5]:\n",
    "    print(token)\n",
    "print(f'\\nText length: {len(doc)}')\n",
    "print(type(doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720e75a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The tallest living man is'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if more than one token is extracted we have a span object\n",
    "span = doc[:5]\n",
    "print(type(span))\n",
    "\n",
    "span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083daaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:   [3, 4, 5, 6, 7, 8, 9]\n",
      "Text:   ['man', 'is', '37', '-', 'year', '-', 'old']\n",
      "is_alpha:   [True, True, False, False, True, False, True]\n",
      "is_punct:   [False, False, False, True, False, True, False]\n",
      "like_num:   [False, False, True, False, False, False, False]\n",
      "Base word:  ['man', 'be', '37', '-', 'year', '-', 'old']\n"
     ]
    }
   ],
   "source": [
    "# spaCy is memory efficient so token and span are just views of doc object there is no duplication\n",
    "# There are also 6 prebuilt in lexical attributes\n",
    "print(\"Index:  \", [token.i for token in doc[3:10]])\n",
    "print(\"Text:  \", [token.text for token in doc[3:10]])\n",
    "print(\"is_alpha:  \", [token.is_alpha for token in doc[3:10]])\n",
    "print(\"is_punct:  \", [token.is_punct for token in doc[3:10]])\n",
    "# like_num recognizes both literal and lettered numbers\n",
    "print(\"like_num:  \", [token.like_num for token in doc[3:10]])\n",
    "# returns base word stripped from any suffixes, prefixes, tense, or other grammatical attributes\n",
    "print(\"Base word: \", [token.lemma_ for token in doc[3:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc27fb",
   "metadata": {},
   "source": [
    "## Architecture and core data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f718e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# we load in a language object which are pre-trained on millions of text instances\n",
    "# available in 22 languages\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ef45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.en.English'>\n"
     ]
    }
   ],
   "source": [
    "# language models can be directly imported from the lan sub-module\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "print(type(nlp))\n",
    "\n",
    "txt = \"\"\"The original name for the search engine Google was Backrub. \n",
    "         It was renamed Google after the googol, \n",
    "         which is the number one followed by 100 zeros.\"\"\"\n",
    "\n",
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a2fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp vocab: <class 'spacy.vocab.Vocab'>\n",
      "doc vocab: <class 'spacy.vocab.Vocab'>\n"
     ]
    }
   ],
   "source": [
    "# after processing text the words and punct are stored in the vocab object of nlp\n",
    "# vocab is shared between docs so all new words are stored in the same object\n",
    "print(f'nlp vocab: {type(nlp.vocab)}')\n",
    "print(f'doc vocab: {type(doc.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7628f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.strings.StringStore'>\n",
      "Hash: 1988622737398120358\n",
      "String: google\n"
     ]
    }
   ],
   "source": [
    "print(type(nlp.vocab.strings))\n",
    "# spaCy communicates in hashes and has a two way lookup table called stringstore\n",
    "google = nlp.vocab.strings[\"google\"]\n",
    "print(f'Hash: {google}')\n",
    "print(f'String: {nlp.vocab.strings[google]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3645c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lexeme.Lexeme"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when tokens enter Vocab they lose context-specific info and become a lexeme\n",
    "lexeme = nlp.vocab[\"google\"]\n",
    "type(lexeme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03bf077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google 1988622737398120358 False\n"
     ]
    }
   ],
   "source": [
    "# does not contain POS tags or morphological dependencies but offer lexical attributes\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3ba01",
   "metadata": {},
   "source": [
    "### Manual Doc Object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac239aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I love Barcelona!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can create docs manually by importing the Doc class from tokens module\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "words = [\"I\", \"love\", \"Barcelona\", \"!\"]\n",
    "spaces = [True, True, False, False]\n",
    "\n",
    "# we combine the words and spaces to create a text doc\n",
    "# doc requires a vocab list before being able to create a doc\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbd81e",
   "metadata": {},
   "source": [
    "### Manual Span Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe04e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n",
      "The original name for the search engine Google was Backrub\n",
      "0 10\n"
     ]
    }
   ],
   "source": [
    "# spans are also a class of their own\n",
    "doc = nlp(txt)\n",
    "\n",
    "span = doc[:10]\n",
    "print(type(span))\n",
    "print(span.text)\n",
    "print(span.start, span.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdcd6afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The original name for the search engine Google was Backrub'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also manually create span objects\n",
    "from spacy.tokens import Span\n",
    "\n",
    "span = Span(doc, 0, 10)\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68200cc",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8be1be64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleopatra               PERSON              \n",
      "Egyptian                NORP                \n",
      "Egypt                   GPE                 \n",
      "Greek                   NORP                \n",
      "Alexander the Great's    ORG                 \n",
      "Macedonian              NORP                \n",
      "Ptolemy                 PERSON              \n"
     ]
    }
   ],
   "source": [
    "# We use spaCy to perform name entity extraction/recognition\n",
    "\n",
    "txt = \"\"\"Cleopatra wasn't actually Egyptian! \n",
    "         As far as historians can tell, Egypt's \n",
    "         famous femme fatal was actually Greek!. \n",
    "         She was a descendant of Alexander the Great's\n",
    "         Macedonian general Ptolemy\"\"\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(txt)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:<20}    {ent.label_:<20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c683e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies, agencies, institutions, etc.\n",
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "# explains the entity labels provided\n",
    "print(spacy.explain('ORG'))\n",
    "print(spacy.explain('GPE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8c2466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cleopatra\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " wasn't actually \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egyptian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "! <br>         As far as historians can tell, \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egypt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s <br>         famous femme fatal was actually \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Greek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "!. <br>         She was a descendant of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alexander the Great's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "<br>         \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Macedonian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " general \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ptolemy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can also display an entity tagger instead of straight text\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aed91103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander the Great\n",
      "Alexander the Great's\n",
      "(Cleopatra, Egyptian, Egypt, Greek, Macedonian, Ptolemy)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cleopatra\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " wasn't actually \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egyptian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "! <br>         As far as historians can tell, \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egypt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s <br>         famous femme fatal was actually \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Greek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "!. <br>         She was a descendant of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alexander the Great\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "'s<br>         \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Macedonian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " general \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ptolemy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alexander the Great is mislabeled as an ORG instead of a person\n",
    "# so we want to relabel it\n",
    "from spacy.tokens import Span\n",
    "alexander = Span(doc, 31, 34, label=\"PERSON\")\n",
    "print(alexander)\n",
    "\n",
    "print(doc[31:35])\n",
    "# to remove a entity we have to first convert it into a separate list and remove the desired value\n",
    "# then we set the original doc.ents to the list to update the removed value\n",
    "test = list(doc.ents)\n",
    "del test[4]\n",
    "doc.ents = test\n",
    "print(doc.ents)\n",
    "doc.set_ents([alexander], default=\"unmodified\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a977bc3",
   "metadata": {},
   "source": [
    "## Predicting part-of-speech (POS) tags and syntatic dependicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26e59394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                 Part-of-speech       Dependency           Dependency text     \n",
      "\n",
      "The                  DET                  det                  footprints          \n",
      "first                ADJ                  amod                 footprints          \n",
      "footprints           NOUN                 nsubj                remain              \n",
      "on                   ADP                  prep                 footprints          \n",
      "the                  DET                  det                  moon                \n",
      "moon                 NOUN                 pobj                 on                  \n",
      "will                 AUX                  aux                  remain              \n",
      "remain               VERB                 ROOT                 remain              \n",
      "there                ADV                  advmod               remain              \n",
      "for                  ADP                  prep                 remain              \n",
      "a                    DET                  quantmod             million             \n",
      "million              NUM                  nummod               years               \n",
      "years                NOUN                 pobj                 for                 \n"
     ]
    }
   ],
   "source": [
    "# spaCy offers a rich selection of tools for grammar analysis\n",
    "txt = \"The first footprints on the moon will remain there for a million years\"\n",
    "\n",
    "doc = nlp(txt)\n",
    "\n",
    "print(\n",
    "    f\"{'Text':<20} {'Part-of-speech':<20} \"\n",
    "    f\"{'Dependency':<20} {'Dependency text':<20}\\n\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<20} {token.pos_:<20} {token.dep_:<20} {token.head.text:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db80820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET --> determiner\n",
      "AUX --> auxiliary\n",
      "ADP --> adposition\n",
      "amod --> adjectival modifier\n",
      "nsubj --> nominal subject\n",
      "nummod --> numeric modifier\n"
     ]
    }
   ],
   "source": [
    "# this may seem confusing but we can also use spaCy to explain the labels \n",
    "\n",
    "pos_tags = [\"DET\", \"AUX\", \"ADP\"]\n",
    "dep_tags = [\"amod\", \"nsubj\", \"nummod\"]\n",
    "\n",
    "for pos in pos_tags:\n",
    "    print(pos, \"-->\", spacy.explain(pos))\n",
    "\n",
    "for dep in dep_tags:\n",
    "    print(dep, \"-->\", spacy.explain(dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ae4dfe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object at 0x0000016AC3CEFCC0>\n",
      "The teddy bear\n",
      "President Theodore Roosevelt\n",
      "he\n",
      "a captured black bear\n",
      "a hunt\n",
      "a stuffed-animal maker\n",
      "a bear\n",
      "it\n",
      "the president\n"
     ]
    }
   ],
   "source": [
    "# spaCy is also able to extract noun chunks\n",
    "\n",
    "\n",
    "txt = \"\"\"The teddy bear is named after President Theodore Roosevelt. \n",
    "         After he refused to shoot a captured black bear on a hunt, \n",
    "         a stuffed-animal maker decided to create\n",
    "         a bear and name it after the president.\"\"\"\n",
    "\n",
    "doc = nlp(txt)\n",
    "\n",
    "print(doc.noun_chunks)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e0c85",
   "metadata": {},
   "source": [
    "## Custom rule-based tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78abd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy won't always recognize text tokens so sometimes we have to declare them ourselves\n",
    "txt = \"\"\"Cleopatra wasn't actually Egyptian! \n",
    "         As far as historians can tell, Egypt's \n",
    "         famous femme fatal was actually Greek!. \n",
    "         She was a descendant of Alexander the Great's\n",
    "         Macedonian general Ptolemy\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b392d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by creating a pattern as a dict\n",
    "# this is the three-token pattern of Alexander the Great\n",
    "pattern = [\n",
    "    {\"IS_ALPHA\": True, \"IS_TITLE\": True},\n",
    "    {\"IS_STOP\": True},\n",
    "    {\"IS_ALPHA\": True, \"IS_TITLE\": True}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a84f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we must create a Matcher object that contains this pattern\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Init the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"TITLED_PERSON\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75bb4b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8382984582166938613, 31, 34)]\n",
      "Alexander the Great\n"
     ]
    }
   ],
   "source": [
    "# we process the text and call the matcher object on the doc object\n",
    "# this will return a list of matches\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(txt)\n",
    "\n",
    "# Find all matches\n",
    "matches = matcher(doc)\n",
    "print(matches)\n",
    "\n",
    "# Iterate over matches in this case just one\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553df37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b367ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
